{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-06T04:18:01.828955Z",
     "start_time": "2024-03-06T04:18:01.633040Z"
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Load XML file\n",
    "tree = ET.parse('../data/WikToR.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# List to store dictionaries\n",
    "pages_list = []\n",
    "\n",
    "# Iterate over each <page> element\n",
    "for page in root.findall('.//page'):\n",
    "    page_dict = {}\n",
    "\n",
    "    # Extract data from each <page> element\n",
    "    page_dict['number'] = page.get('number')\n",
    "    page_dict['pageTitle'] = page.find('pageTitle').text\n",
    "    page_dict['toponymName'] = page.find('toponymName').text\n",
    "    page_dict['text'] = page.find('text').text\n",
    "    page_dict['url'] = page.find('url').text\n",
    "    page_dict['lat'] = page.find('lat').text\n",
    "    page_dict['lon'] = page.find('lon').text\n",
    "    page_dict['feature'] = page.find('feature').text\n",
    "    page_dict['country'] = page.find('country').text\n",
    "\n",
    "    # Extract data from <toponymIndices>\n",
    "    toponym_indices = []\n",
    "    for toponym in page.findall('.//toponymIndices/toponym'):\n",
    "        index_dict = {\n",
    "            'start': int(toponym.find('start').text),\n",
    "            'end': int(toponym.find('end').text)\n",
    "        }\n",
    "        toponym_indices.append(index_dict)\n",
    "    page_dict['toponymIndices'] = toponym_indices\n",
    "\n",
    "    # Append page dictionary to the list\n",
    "    pages_list.append(page_dict)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "5000"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T04:18:02.097097Z",
     "start_time": "2024-03-06T04:18:02.091334Z"
    }
   },
   "id": "2c4468e5d16d7fed",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/miniconda3/envs/geonlp/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/thomas/miniconda3/envs/geonlp/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from genre.trie import Trie\n",
    "\n",
    "# load the prefix tree (trie)\n",
    "with open(\"../data/kilt_titles_trie_dict.pkl\", \"rb\") as f:\n",
    "    trie = Trie.load_from_dict(pickle.load(f))\n",
    "\n",
    "from genre.hf_model import GENRE\n",
    "\n",
    "model = GENRE.from_pretrained(\"../models/hf_entity_disambiguation_aidayago\").eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T04:18:20.848331Z",
     "start_time": "2024-03-06T04:18:02.545981Z"
    }
   },
   "id": "c4a89df2c6eb82b8",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def get_coordinates(place_name):\n",
    "    S = requests.Session()\n",
    "\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "    PARAMS = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": place_name,\n",
    "        \"prop\": \"coordinates\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        R = S.get(url=URL, params=PARAMS)\n",
    "        DATA = R.json()\n",
    "        PAGES = DATA['query']['pages']\n",
    "\n",
    "        for k, v in PAGES.items():\n",
    "            coordinates = v.get('coordinates')\n",
    "            if coordinates:\n",
    "                lat = coordinates[0]['lat']\n",
    "                lon = coordinates[0]['lon']\n",
    "                return lat, lon\n",
    "        print(f\"Coordinates not found for {place_name}\")\n",
    "        return 0, 0\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        return 0, 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T04:18:20.853538Z",
     "start_time": "2024-03-06T04:18:20.849839Z"
    }
   },
   "id": "4665ffbbfab0ecaf",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the Earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    radius_of_earth = 6371  # Radius of the Earth in kilometers\n",
    "    distance = radius_of_earth * c\n",
    "\n",
    "    return distance"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T04:18:20.858313Z",
     "start_time": "2024-03-06T04:18:20.854433Z"
    }
   },
   "id": "755a7d45d7ac6666",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_error = 20039"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T04:49:39.560698Z",
     "start_time": "2024-03-06T04:49:39.558356Z"
    }
   },
   "id": "6e5e29334381f535",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "res_distances = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T04:49:40.466775Z",
     "start_time": "2024-03-06T04:49:40.464222Z"
    }
   },
   "id": "8cdf1b87b9b02e8b",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pages_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Iterate over the modified list of dictionaries\u001B[39;00m\n\u001B[1;32m      2\u001B[0m iter_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m page_dict \u001B[38;5;129;01min\u001B[39;00m \u001B[43mpages_list\u001B[49m:\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(page_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpageTitle\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      5\u001B[0m     text \u001B[38;5;241m=\u001B[39m page_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pages_list' is not defined"
     ]
    }
   ],
   "source": [
    "# Iterate over the modified list of dictionaries\n",
    "iter_count = 0\n",
    "for page_dict in pages_list:\n",
    "    print(page_dict['pageTitle'])\n",
    "    text = page_dict['text']\n",
    "    for index_pair in page_dict['toponymIndices']:\n",
    "        iter_count+=1\n",
    "        if iter_count <= len(res_distances):\n",
    "            continue\n",
    "\n",
    "        start_index = index_pair['start']\n",
    "        end_index = index_pair['end']\n",
    "        modified_text = text[:start_index] + \" [START_ENT] \" + text[start_index:end_index] + \" [END_ENT] \" + text[\n",
    "                                                                                                             end_index:]\n",
    "\n",
    "        sentences = [modified_text]\n",
    "        res = model.sample(\n",
    "            sentences,\n",
    "            prefix_allowed_tokens_fn=lambda batch_id, sent: trie.get(sent.tolist()),\n",
    "        )\n",
    "        # pprint(res)\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        if res[0][0][\"text\"] == page_dict['pageTitle']:\n",
    "            # print(\"\\tCorrect\")\n",
    "            dist = 0.0\n",
    "        else:\n",
    "            print(f\"\\tIncorrect. Got: {res[0][0]['text']}\")\n",
    "            lat, lon = get_coordinates(res[0][0][\"text\"])\n",
    "            if lat == 0 and lon == 0:  # use max_error if predicted entity is not a place\n",
    "                dist = max_error\n",
    "            else:\n",
    "                dist = haversine_distance(round(float(page_dict['lat']), 2), round(float(page_dict['lon']), 2),\n",
    "                                          round(lat, 2), round(lon, 2))\n",
    "\n",
    "        res_distances.append(dist)\n",
    "\n",
    "        # print(\"\\t\" + str(dist))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T06:09:20.688608Z",
     "start_time": "2024-03-06T06:09:20.450210Z"
    }
   },
   "id": "2920dc0cd1692de2",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/wiktor_distances.pkl\", 'wb') as f:\n",
    "        pickle.dump(res_distances, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T05:58:01.390926Z",
     "start_time": "2024-03-06T05:58:01.387800Z"
    }
   },
   "id": "2c92bdbfc6222daa",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_accuracy_at_161km(distances):\n",
    "    \"\"\"\n",
    "    Compute Accuracy@161km from a list of distances.\n",
    "    \"\"\"\n",
    "    count_within_threshold = sum(1 for distance in distances if distance <= 161)\n",
    "    accuracy = count_within_threshold / len(distances)\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac51124701e58ede"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_mean_error(distances):\n",
    "    \"\"\"\n",
    "    Compute the mean error from a list of distances.\n",
    "    \"\"\"\n",
    "    mean_error = sum(distances) / len(distances)\n",
    "\n",
    "    return mean_error"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f95c8ac154ba9db"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from numpy import trapz\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_auc(distances):\n",
    "    \"\"\"\n",
    "    Compute the Area Under the Curve (AUC) given list of distance.\n",
    "    \"\"\"\n",
    "    distances.sort()\n",
    "    dim_error = [(np.log(x + 1) / np.log(max_error)) for x in distances]\n",
    "    y = np.array(dim_error)\n",
    "\n",
    "    # Compute the area using the composite trapezoidal rule.\n",
    "    area = trapz(y) / len(distances)\n",
    "    return area"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a14df9ba4f5d386"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "compute_accuracy_at_161km(res_distances)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaf3e88f5c090451"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "compute_mean_error(res_distances)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "821ffe0273003f72"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "compute_auc(res_distances)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d5db683b3af7e53"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
