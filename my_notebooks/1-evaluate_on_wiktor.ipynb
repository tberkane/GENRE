{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-07T06:03:46.122101Z",
     "start_time": "2024-03-07T06:03:45.907318Z"
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Load XML file\n",
    "tree = ET.parse('../data/WikToR.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# List to store dictionaries\n",
    "pages_list = []\n",
    "\n",
    "# Iterate over each <page> element\n",
    "for page in root.findall('.//page'):\n",
    "    page_dict = {}\n",
    "\n",
    "    # Extract data from each <page> element\n",
    "    page_dict['number'] = page.get('number')\n",
    "    page_dict['pageTitle'] = page.find('pageTitle').text\n",
    "    page_dict['toponymName'] = page.find('toponymName').text\n",
    "    page_dict['text'] = page.find('text').text\n",
    "    page_dict['url'] = page.find('url').text\n",
    "    page_dict['lat'] = page.find('lat').text\n",
    "    page_dict['lon'] = page.find('lon').text\n",
    "    page_dict['feature'] = page.find('feature').text\n",
    "    page_dict['country'] = page.find('country').text\n",
    "\n",
    "    # Extract data from <toponymIndices>\n",
    "    toponym_indices = []\n",
    "    for toponym in page.findall('.//toponymIndices/toponym'):\n",
    "        index_dict = {\n",
    "            'start': int(toponym.find('start').text),\n",
    "            'end': int(toponym.find('end').text)\n",
    "        }\n",
    "        toponym_indices.append(index_dict)\n",
    "    page_dict['toponymIndices'] = toponym_indices\n",
    "\n",
    "    # Append page dictionary to the list\n",
    "    pages_list.append(page_dict)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "5000"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T06:03:46.127561Z",
     "start_time": "2024-03-07T06:03:46.123178Z"
    }
   },
   "id": "2c4468e5d16d7fed",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/miniconda3/envs/geonlp/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/thomas/miniconda3/envs/geonlp/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from genre.trie import Trie\n",
    "\n",
    "# load the prefix tree (trie)\n",
    "with open(\"../data/kilt_titles_trie_dict.pkl\", \"rb\") as f:\n",
    "    trie = Trie.load_from_dict(pickle.load(f))\n",
    "\n",
    "from genre.hf_model import GENRE\n",
    "\n",
    "model = GENRE.from_pretrained(\"../models/hf_entity_disambiguation_aidayago\").eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T06:04:10.002688Z",
     "start_time": "2024-03-07T06:03:46.128498Z"
    }
   },
   "id": "c4a89df2c6eb82b8",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def get_coordinates(place_name):\n",
    "    S = requests.Session()\n",
    "\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "    PARAMS = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": place_name,\n",
    "        \"prop\": \"coordinates\"\n",
    "    }\n",
    "\n",
    "    # try:\n",
    "    R = S.get(url=URL, params=PARAMS)\n",
    "    DATA = R.json()\n",
    "    PAGES = DATA['query']['pages']\n",
    "\n",
    "    for k, v in PAGES.items():\n",
    "        coordinates = v.get('coordinates')\n",
    "        if coordinates:\n",
    "            lat = coordinates[0]['lat']\n",
    "            lon = coordinates[0]['lon']\n",
    "            return lat, lon\n",
    "    print(f\"Coordinates not found for {place_name}\")\n",
    "    return 0, 0\n",
    "    # except Exception as e:\n",
    "    #     print(\"An error occurred:\", e)\n",
    "    #     return 0, 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T06:04:10.008905Z",
     "start_time": "2024-03-07T06:04:10.004529Z"
    }
   },
   "id": "4665ffbbfab0ecaf",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the Earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    radius_of_earth = 6371  # Radius of the Earth in kilometers\n",
    "    distance = radius_of_earth * c\n",
    "\n",
    "    return distance"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T06:04:10.014045Z",
     "start_time": "2024-03-07T06:04:10.009656Z"
    }
   },
   "id": "755a7d45d7ac6666",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def shorten_sentences(string, start_pos, end_pos):\n",
    "    \"\"\"\n",
    "    Best effort (:\n",
    "    :param string: \n",
    "    :param start_pos: \n",
    "    :param end_pos: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    left_boundary = max(0, start_pos - 1500)\n",
    "    right_boundary = min(len(string), end_pos + 1500)\n",
    "\n",
    "    context_string = string[left_boundary:right_boundary]\n",
    "    \n",
    "    return context_string"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T06:04:10.018478Z",
     "start_time": "2024-03-07T06:04:10.014777Z"
    }
   },
   "id": "2228d892feca9b9",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_error = 20039"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T06:04:10.021907Z",
     "start_time": "2024-03-07T06:04:10.019481Z"
    }
   },
   "id": "6e5e29334381f535",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "res_distances = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T06:04:10.025737Z",
     "start_time": "2024-03-07T06:04:10.022915Z"
    }
   },
   "id": "8cdf1b87b9b02e8b",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/wiktor_distances.pkl\", 'rb') as f:\n",
    "    res_distances = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T06:04:10.030673Z",
     "start_time": "2024-03-07T06:04:10.026998Z"
    }
   },
   "id": "ee92d1af46421156",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T06:04:10.035427Z",
     "start_time": "2024-03-07T06:04:10.032977Z"
    }
   },
   "id": "40a2265738dd35b7",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates not found for Pangi\n",
      "Coordinates not found for Pangi\n",
      "Coordinates not found for Pangi\n",
      "Coordinates not found for Pangi\n",
      "Coordinates not found for Pangi\n",
      "Coordinates not found for Pangal\n",
      "Coordinates not found for Pangi\n",
      "Coordinates not found for San Manuel\n",
      "Coordinates not found for Campo, Ticino\n",
      "Coordinates not found for Campo, Ticino\n",
      "Coordinates not found for Campo, Ticino\n",
      "Coordinates not found for Campo, Ticino\n",
      "Coordinates not found for Campo, Ticino\n",
      "\t4100 iterations completed, saving to pkl.\n",
      "Coordinates not found for Fortuna\n",
      "Coordinates not found for La Fortuna\n",
      "Coordinates not found for La Fortuna\n",
      "\t4200 iterations completed, saving to pkl.\n",
      "Coordinates not found for Waipa District\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the modified list of dictionaries\n",
    "iter_count = 0\n",
    "for page_dict in pages_list:\n",
    "    # print(page_dict['pageTitle'])\n",
    "    text = page_dict['text']\n",
    "    for index_pair in page_dict['toponymIndices']:\n",
    "        iter_count += 1\n",
    "        if iter_count <= len(res_distances):\n",
    "            continue\n",
    "\n",
    "        start_index = index_pair['start']\n",
    "        end_index = index_pair['end']\n",
    "        modified_text = text[:start_index] + \" [START_ENT] \" + text[start_index:end_index] + \" [END_ENT] \" + text[\n",
    "                                                                                                             end_index:]\n",
    "\n",
    "        sentences = [modified_text]\n",
    "        try:\n",
    "            res = model.sample(\n",
    "                sentences,\n",
    "                prefix_allowed_tokens_fn=lambda batch_id, sent: trie.get(sent.tolist()),\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Input text too long, shortening it.\")\n",
    "            modified_text = shorten_sentences(modified_text, start_index, end_index+14)\n",
    "            sentences = [modified_text]\n",
    "            res = model.sample(\n",
    "                sentences,\n",
    "                prefix_allowed_tokens_fn=lambda batch_id, sent: trie.get(sent.tolist()),\n",
    "            )\n",
    "        # pprint(res)\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        if res[0][0][\"text\"] == page_dict['pageTitle']:\n",
    "            # print(\"\\tCorrect\")\n",
    "            dist = 0.0\n",
    "        else:\n",
    "            # print(f\"\\tIncorrect. Got: {res[0][0]['text']}\")\n",
    "            lat, lon = get_coordinates(res[0][0][\"text\"])\n",
    "            if lat == 0 and lon == 0:  # use max_error if predicted entity is not a place\n",
    "                dist = max_error\n",
    "            else:\n",
    "                dist = haversine_distance(round(float(page_dict['lat']), 2), round(float(page_dict['lon']), 2),\n",
    "                                          round(lat, 2), round(lon, 2))\n",
    "\n",
    "        res_distances.append(dist)\n",
    "        \n",
    "        if iter_count % 100 == 0:\n",
    "            print(f\"\\t{iter_count} iterations completed, saving to pkl.\")\n",
    "            with open(\"../data/wiktor_distances.pkl\", 'wb') as f:\n",
    "                pickle.dump(res_distances, f)\n",
    "\n",
    "        # print(\"\\t\" + str(dist))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-07T06:04:10.036491Z"
    }
   },
   "id": "2920dc0cd1692de2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res_distances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpickle\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/wiktor_distances.pkl\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m----> 4\u001B[0m     pickle\u001B[38;5;241m.\u001B[39mdump(\u001B[43mres_distances\u001B[49m, f)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'res_distances' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/wiktor_distances.pkl\", 'wb') as f:\n",
    "    pickle.dump(res_distances, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T08:48:21.220609Z",
     "start_time": "2024-03-06T08:48:21.205046Z"
    }
   },
   "id": "2c92bdbfc6222daa",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_accuracy_at_161km(distances):\n",
    "    \"\"\"\n",
    "    Compute Accuracy@161km from a list of distances.\n",
    "    \"\"\"\n",
    "    count_within_threshold = sum(1 for distance in distances if distance <= 161)\n",
    "    accuracy = count_within_threshold / len(distances)\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac51124701e58ede"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_mean_error(distances):\n",
    "    \"\"\"\n",
    "    Compute the mean error from a list of distances.\n",
    "    \"\"\"\n",
    "    mean_error = sum(distances) / len(distances)\n",
    "\n",
    "    return mean_error"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f95c8ac154ba9db"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from numpy import trapz\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_auc(distances):\n",
    "    \"\"\"\n",
    "    Compute the Area Under the Curve (AUC) given list of distance.\n",
    "    \"\"\"\n",
    "    distances.sort()\n",
    "    dim_error = [(np.log(x + 1) / np.log(max_error)) for x in distances]\n",
    "    y = np.array(dim_error)\n",
    "\n",
    "    # Compute the area using the composite trapezoidal rule.\n",
    "    area = trapz(y) / len(distances)\n",
    "    return area"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a14df9ba4f5d386"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "compute_accuracy_at_161km(res_distances)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaf3e88f5c090451"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "compute_mean_error(res_distances)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "821ffe0273003f72"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "compute_auc(res_distances)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d5db683b3af7e53"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
